{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 시작하기!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교재 : Deep Learning from scratch 밑바닥부터 시작하는 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오늘의 챕터 1 ~ 3 단원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chap 1. 간단히 numpy\n",
    "\n",
    "numpy는 파이썬의 자료형 list보다 좀 더 편리하게 행렬 연산을 할 수 있게 해주는\n",
    "\n",
    "매우 좋은 파이썬 외부 라이브러리 입니다.\n",
    "\n",
    "넘파이를 쓰기위해서 numpy를 깔고 import를 해줘야합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 넘파이 배열 생성하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.array() 메소드로 넘파이 배열을 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.],\n",
       "       [ 4.,  5.,  6.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 x 2 행렬 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.array([[1,2],[3,4]])\n",
    "\n",
    "B = np.array([[4,5],[6,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[4 5]\n",
      " [6 7]]\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 행렬의 모양 알아보기 \n",
    " ( 행 , 열)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행렬 사칙연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 고등학교 때 배운 그 행렬 사칙연산 맞습니다...!\n",
    "\n",
    "아시죠...?ㅎㅎ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 10],\n",
       "       [18, 28]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  7],\n",
       "       [ 9, 11]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3, -3],\n",
       "       [-3, -3]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A - B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25      ,  0.4       ],\n",
       "       [ 0.5       ,  0.57142857]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 선행대수학 공부하고 싶은 사람은 아래 링크로!\n",
    "\n",
    "ps. 딥러닝하려면 행렬 연산이랑 벡터 미분을 할 줄 알아야 합니다...ㅠ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬으로 선형대수학 하기: [https://www.slideshare.net/ssuser7e10e4/linear-algrbra](https://www.slideshare.net/ssuser7e10e4/linear-algrbra)\n",
    "\n",
    "파이썬으로 행렬(벡터) 미분하기: [https://www.slideshare.net/ssuser7e10e4/matrix-calculus](https://www.slideshare.net/ssuser7e10e4/matrix-calculus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 넘파이의 브로드캐스팅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 생성한 nparray 타입의 데이터는 어떻게 알아서 사칙연산을 하는거지...?\n",
    "\n",
    "그니까 벡터의 스칼라곱, 덧셈이 어떻게 가능하냔 말이다...\n",
    "\n",
    "넘파이의 브로드캐스팅이 그걸해준다!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chap 2. 퍼셉트론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 갑자기 퍼셉트론은 왜 나오는거지..?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 퍼셉트론은 신경망(딥러닝)의 기원이 되는 알고리즘 이기 때문..!\n",
    "- 퍼셉트론의 구조를 배우는 것은 신경망과 딥러닝을 배우는데 중요한 아이디어가 된다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그래서 퍼셉트론은 뭔가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 퍼셉트론은 다수의 신호를 입력받아서 하나의 신호로 출력하는 것\n",
    "- 여기서 신호란 강물처럼 흐름이 있는 것을 생각하면 된다\n",
    "- 퍼셉트론은 신호를 받아서 흐름을 만들고 그 정보를 앞으로 전달한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실제 전류와 다른점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 신호가 흐른다(1) 안흐른다(0) 두가지의 값을 가진다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![퍼셉트론](./img/perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망( neural network) 시작하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그럼 퍼셉트론에서 신경망은 뭐가 다른가?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망에서 활성화 함수( activation function)가 도입된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![신경망](./img/activation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 활성화 함수 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "활성화 함수란? \n",
    "\n",
    "> 입계값( threashold )를 경계로 출력이 바뀌는 함수\n",
    "\n",
    "X 값과 weight 값을 곱해서 합한 값이 일정 값(임계값)을 넘었을 때 그 뉴런은 활성화 된다..!\n",
    "\n",
    "그냥 직관적으로 전구가 켜지냐 안켜지냐로 생각하면 쉽다\n",
    "\n",
    "임계값을 넘으면 불이켜지고 임계값을 넘지 않으면 안켜지는...(물론 계단함수와 같은 형태일때 해당하는 것이다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 딥러닝에서 활성화 함수의 종류가 많다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![활성화함수](./img/activation_fn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시그모이드( sigmoid) 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시그모이드 함수는 아래 그림의 식의 형태를 띄고 있으며 결과로 0과 1사이의 실수를 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![시그모이드](./img/sigmoid.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시그모이드 함수 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 백터 만들어서 시그모이드 함수에 넣어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26894142,  0.73105858,  0.88079708])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([-1.0, 1.0, 2.0])\n",
    "\n",
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망( neural network) 구조 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "신경망을 이해하기 위해 입력층(input layer)과 은닉층(hidden layer)이 어떻게 행렬 곱 되는지 이해해야 합니다.\n",
    "\n",
    "- 입력층(input layer) : 말 그대로 데이터가 입력 되는 층 \n",
    "\n",
    "- 은닉층(hidden layer) : 입력층과 출력층 사이에 위치한 신경망 층들...이게 딥(deep)하면 딥러닝이라 부른다..!\n",
    "\n",
    "- 출력층(output layer) : 입력층에 들어온 데이터가 딥한 은닉층들을 거쳐서 최종 뉴럴넷이 예측하고 싶은 값을 나타내는 층!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![layer](./img/layer.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망(neural network) 연산은 행렬 곱 연산과 같습니다.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수식은 latex를 익히고 넣도록 하겠습니다....\n",
    "\n",
    "칠판으로 설명을....ㅠ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파이썬 코드로 이해하여 봅시다!\n",
    "### 행렬곱으로 뉴런 하나 만들기!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 입력층에서 첫번쨰 은닉층으로 신호 전달하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X 는 입력층의 값으로 [1.0, 0.5] 두가지 값을 갖습니다.\n",
    "\n",
    "W1 는 가중치(weight)값을 의미합니다.\n",
    "\n",
    "   W1은 2 by 3 matrix로 표현되어 있습니다.\n",
    "       \n",
    "       [0.1, 0.3, 0.5] 와 [0.2, 0.4, 0.6] 가 아래 뉴럴 네트워크 구조에서 어떠한 값을 의미하는지 이해하도록 노력하면 됩니다.\n",
    "\n",
    "B1 는 활성화 함수가 활성이 잘되게 해주는 역할을 합니다. bias라고 부릅니다. \n",
    "\n",
    "B1은 첫번째 은닉층에 있는 세개의 노드에 mapping되는 [0.1, 0.2, 0.3] 값들을 갖습니다. \n",
    "\n",
    "ps. 나중에 배우겠지만 뉴럴넷이 예측한 값(predictec value)와 실제값(real value) 값과의 차이도 bias라고 부릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1.0, 0.5])\n",
    "\n",
    "W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "\n",
    "B1 = np.array([0.1, 0.2, 0.3])\n",
    "\n",
    "print(W1.shape)\n",
    "print(X.shape)\n",
    "print(B1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![neural](./img/neural_1.jpg '입력층')\n",
    "\n",
    "                                              [입력층에서 첫번째 은닉층으로 신호 전달]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 은닉층에서 보이는 a는 **가중치의 합( weight + bias )**을 의미합니다.\n",
    "\n",
    "a = 가중치 합( weight + bias )\n",
    "\n",
    "파이썬 코드에서 np.dot()은 a를 행렬의 내적(inner product)을 구해줍니다\n",
    "\n",
    "z는 활성함수를 통해 나온 값을 의미합니다. 앞서 뉴런 하나 짜리에서 입력의 벡터와 가중치 벡터의 product를 sigmoid function에 넣었을 때 나오는 결과가 바로 activation이고 이 노트에서는 z로 표기합니다.\n",
    "\n",
    "출처: http://woongheelee.com/entry/인공-신경망에-관한-설명-스탠포드-대학-앤드류-응-교수의-sparse-autoencoder-정리-노트로-인공신경망-이해하기 [노트정리]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3  0.7  1.1]\n"
     ]
    }
   ],
   "source": [
    "A1 = np.dot(X, W1) + B1\n",
    "\n",
    "print(A1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 활성화 함수에 가중치 합 넣기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        아래 Z1은 첫번째 은닉층에서 가중치 합으로 나온 a1, a2, a3 세가지 값을 시그모이드 함수(activation)에 넣은 결과입니다! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3  0.7  1.1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'첫번째 은닉층에 있는 뉴런들을 각각 활성화함수에 넣은 결과 : [ 0.57444252  0.66818777  0.75026011]'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1 = sigmoid(A1)\n",
    "\n",
    "print(A1)\n",
    "\n",
    "'첫번째 은닉층에 있는 뉴런들을 각각 활성화함수에 넣은 결과 : {}'.format(Z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자..그러면 드디어 첫번째 은닉층의 뉴런 값을 구했습니다!!!!!\n",
    "### 이제 두번째 은닉층의 뉴런값을 구해야합니다...ㅠㅠ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 첫번째 은닉층에서 두번째 은닉층으로 신호 전달하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(2,)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
    "\n",
    "B2 = np.array([0.1, 0.2])\n",
    "\n",
    "print(Z1.shape)\n",
    "print(B2.shape)\n",
    "print(W2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51615984  1.21402696]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'두번째 은닉층에 있는 뉴런들을 각각 활성화함수에 넣은 결과 : [ 0.62624937  0.7710107 ]'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2 = np.dot(Z1, W2) + B2\n",
    "\n",
    "Z2 = sigmoid(A2)\n",
    "\n",
    "print(A2)\n",
    "'두번째 은닉층에 있는 뉴런들을 각각 활성화함수에 넣은 결과 : {}'.format(Z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![neural_2](./img/neural_2.jpg '입력층')\n",
    "\n",
    "                                              [첫번째 은닉층에서 두번째 은닉층으로 신호 전달]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 출력층으로 신호전달하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종적으로 두번째 은닉층에서 출력층으로 가중치 행렬 내적을 계산하여 값을 구해보겠습니다.\n",
    "\n",
    "지금까지 해온 방법과 똑같으며 딱하나 다른것은\n",
    "\n",
    "출력층의 활성화 함수로 identity_function에 넣어줬다는 것입니다.\n",
    "\n",
    "        identity_function은 항등 함수를 의미하고 그냥 값을 넣어준대로 뱉어주는 함수입니다...\n",
    "        \n",
    "        \n",
    "뒤에서 소프트맥스 함수를 이용해서 출력층의 값들을 0 ~ 1 사이의 확률로 나타내주는 활성화 함수를 이용할 것입니다 !!!\n",
    "\n",
    "\n",
    "> 출력층의 활성화 함수는 풀고자하는 문제의 설질에 맞게 정의합니다. 예를들어 회귀에서는 항등함수를 이용하고, 2 클래스 분류 문제에서는 시그모이드 함수를 이용하고, 다중 클래스 분류에서는 소프트 맥스 함수를 이용합니다.\n",
    "\n",
    "\n",
    "그리고 입력층의 갯수와 출력층의 갯수는 같지 않아도 됩니다!\n",
    "\n",
    "뉴럴 네트워크 설계하는 사람 마음입니다..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'출력층 뉴런들의 값 : [ 0.31682708  0.69627909]'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "W3 = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "\n",
    "B3 = np.array([0.1, 0.2])\n",
    "\n",
    "A3 = np.dot(Z2, W3) + B3\n",
    "\n",
    "Y = identity_function(A3)\n",
    "\n",
    "'출력층 뉴런들의 값 : {}'.format(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 3층 신경망 구현 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'뉴럴 네트워크가 예측한 값 : [ 0.31682708  0.69627909]'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "    network['b1'] = np.array([0.1, 0.2, 0.3])\n",
    "    network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
    "    network['b2'] = np.array([0.1, 0.2])\n",
    "    network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "    network['b3'] = np.array([0.1, 0.2])\n",
    "    \n",
    "    return network\n",
    "\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    a1 = np.dot(x , W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = identity_function(a3)\n",
    "    \n",
    "    return y\n",
    "\n",
    "network = init_network()\n",
    "\n",
    "# 입력층 X\n",
    "x = np.array([1.0, 0.5])\n",
    "y = forward(network, x)\n",
    "'뉴럴 네트워크가 예측한 값 : {}'.format(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
