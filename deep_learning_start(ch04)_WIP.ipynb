{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 시작하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chap 4. 신경망 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망으로 어떻게 데이터를 학습시킬까를 공부해 볼 수 있는 차례가 왔습니다. 신경망에서 학습이란 cost 함수를 줄여주는 weight값을 찾아가는 과정입니다.\n",
    "\n",
    "여기서 cost 함수 개념이 도입됩니다. 어떻게 weight값들을 줄어 나갈 수 있을까요~?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 데이터에서 학습한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 신경망을 representation learning이라고도 부른다. 이유는 데이터를 보고 학습할 수 있기 때문.\n",
    "- 신경망이 데이터를 보고 weight값을 조정해서 cost 함수를 줄여나간다. \n",
    "\n",
    "- 신경망이 깊어질수록 weight값들을 증가한다. 당연히 뉴런과 뉴런을 이어주는 시냅스가 증가하기 때문! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 데이터 주도학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기계학습은 데이터에서 패턴을 찾고 데이터로 이야기 하는 것\n",
    "- 신경망과 딥러닝은 기존 머신러닝에서 사용하던 방법보다 사람의 개입을 더욱 배제하길 원하는(?) 특징을 가지고 있다. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (내의견) 기존 머신러닝은 feature engineer이 정말 중요한 요소였다. 데이터 전처리 작업이라고 부르는데 이 작업이 머신러닝 작업에서 70~80%를 차지할 정도로 비중이 큰 작업이었다. 실제 알고리즘을 돌려보는 작업은 전체작업의 20%정도밖에 안될 정도로 tidy하고 clean한 데이터를 기계학습 알고리즘에 넣어주는 것이 중요했다. 물론 이 방법이 아직도 유효하고 머신러닝에 정말 중요한 이슈이다. 하지만 딥러닝은 end-to-end learning이라고 부른다. 데이터를 넣어주고 feature를 추출해주는 작업까지 해주는 것이다. 하지만 딥러닝에 넣어주는 데이터도 tidy하고 clean할 수록 성능이 높아지는건 예외가 아닐 것이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5를 인식하는 알고리즘을 예제로 들겠다. \n",
    "- 사람이 보기에는 5라는 숫자를 인식하는데 어려움이 없지만 기계는 어떤 알고리즘으로 5를 인식시키게 할지 방법이 필요하다.\n",
    "- 한가지 방법으로 이미지에서 feature를 추출한다.\n",
    "- 이미지의 특징은 보통 벡터로 표현한다.\n",
    "- 영상처리 분야에서 feature engineering기법으로 SIFT, SURF, HOG등의 방법이 쓰인다.\n",
    "- 이러한 기법으로 feature를 추출하고 SVM, KNN등으로 학습시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지를 벡터로 변환하는 작업은 역시 '사람'이 하는 작업이다.\n",
    "- 좋은 feature를 추출하지 못하면 좋은 성능을 내지 못한다.\n",
    "- 딥러닝 이전까지 기계학습은 이러한 feature 추출이 주된 일이었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 훈련 데이터와 시험 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기계학습에서 데이터를 training set과 test set으로 나누어 학습과 테스트를 진행한다\n",
    "- training set을 이용해서 최적의 파라미터를 찾는다.\n",
    "- test set을 이용해 trained 된 모델을 테스트한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋을 나누는 이유는?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 범용적으로 사용할 수 있는 모델을 만들기 위해서!\n",
    "- genaralization 시키기 위해 test set을 분리하는 것이다.\n",
    "- 범용적이라는 말은 아직 마주치치 못한 데이터에 대해서도 모델의 성능을 발휘하기 위해서이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 오버피팅이란?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- training set에만 지나치게 최적화된 상태를 overfitting이라 한다.\n",
    "- 오버피팅은 기계학습의 매우매우 중요한 과제이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 손실함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최적의 파라미터 값을 찾는 지표로 손실함수(cost function)을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 평균제곱오차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 많이 쓰이는 손실함수로 mse(평균제곱오차) 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 소프트맥스 함수의 출력 => 확률로 해석할 수 있으므로 0일 확률은 0.1, 1일 확률은 0.05 ...이다.\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "# 숫자 0부터 9까지 정답 레이블이다. 여기서 숫자 2가 정답이다.\n",
    "# 한 원소만 1로 하고 그 외 값은 1로 하는 것을 one-hot encoding이라 한다.\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평균제곱오차 함수 구현\n",
    "각 원소의 출력값과 정답 레이블의 차를 제곱한 후, 그 총합을 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 출력(추정 값)이 '2'인 경우에 가장 높다. 즉, 출력과 정답이 같을 때 에러가 적다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59750000000000003"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 정답이 2일때\n",
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 정답은 똑같이 '2'지만 신경망의 출력은 7이므로 에러가 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59750000000000003"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답이 7일 확률이 높다고 추정했을 경우\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "\n",
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 교차 엔트로피 교차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                            E = -sigma(t_k * log(y_k))\n",
    "\n",
    "- t_k는 정답에 해당하는 인덱스의 원소만 1이고 나머지는 0이다.(원-핫 인코딩)\n",
    "- 정답일 떄만 출력(추정 값)의 자연로그를 계산하는 식!\n",
    "- ex) 정답이 '2'일때, 출력(추정 값)이 0.6 일떄, 교차 엔트로피 오차는 -log(0.6) = 0.51\n",
    "- ex) 정답이 '2'일때, 출력(추정 값)이 0.1 일때, 교차 엔트로피 오차는 -log(0.1) = 2.30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결론, 교차 엔트로피 오차는 정답일 때의 출력이 전체 값을 정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 교차 엔트로피 함수 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- y와 t는 넘파이 배열\n",
    "- np.log를 계산할 때 아주 작은 값인 delta를 더함 ==> np.log()에 0을 입력하면 마이너스 무한대를 뜻하는 -inf가 되서 그걸 방지하기 위해서!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entory_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정답이 '2' 일때, 출력이 0.6인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51082545709933802"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "\n",
    "cross_entory_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정답이 '2' 일때, 출력이 0.1인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3025840929945458"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "cross_entory_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 미니배치 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기계학습은 training set을 통해 학습을 한다. \n",
    "- training set에 대한 손실함수 값을 구하고, 그 값을 줄여주는 파라미터를 찾아낸다.\n",
    "- 그러므로, 모든 training set을 대상으로 손실 함수 값을 구해야한다.\n",
    "- 만약, 데이터가 100개일 때, 100개의 손실 함수 값들의 합을 지표로 삼는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training set 모두에 대한 손실 함수의 값을 구해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                 E = -1/N * sigma_n(sigma_k(t_nk * log(y_nk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터의 총 합은 N\n",
    "- t_nk == n번째 데이터의 k차원 째의 값\n",
    "- 데이터 하나의 손실함수를 N개의 데이터로 확장 한것.\n",
    "- N으로 나누어 '평균 손실 함수'를 구한다.\n",
    "- 평균 손실 함수를 쓰면 데이터의 갯수와 상관없이 언제든 통일된 지표를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그런데, 데이터가 엄청엄청 많아지면 다 계산해야 하나??\n",
    "- 현실적이지 않다. 많은 데이터 중에 일부를 샘플링해서 전체의 '근사치'로 사용한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   #### 이를 미니배치(mini_batch)라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 코드 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "sys.path.insert(0, './deep-learning-from-scratch/')\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize = True, one_hot_label = True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
